{
  "id": 4,
  "title": "فهم وتكوين ملف robots.txt",
  "image": "robots-txt.webp",
  "excerpt": "تعرف على كيفية إنشاء وتكوين ملف robots.txt للتحكم في كيفية زحف محركات البحث إلى موقعك.",
  "content": "<p><img src=\"/assets/images/articles/robot.png\" alt=\"لقطة شاشة لخطأ في ملف robots.txt غير صالح\" style=\"display:block; margin:20px auto; max-width:100%; border-radius:8px;\"/> يعد ملف <code>robots.txt</code> عنصرًا أساسيًا للتحكم في كيفية وصول محركات البحث إلى موقعك. يسمح لك بتحديد الأجزاء التي يجب أو لا يجب أن تزحف إليها الروبوتات.</p><h3>1. لماذا نستخدم ملف robots.txt؟</h3><p>فيما يلي الأسباب الرئيسية لاستخدام ملف <code>robots.txt</code>:</p><ul><li><strong>تحسين SEO:</strong> منع فهرسة الصفحات غير الضرورية أو الحساسة.</li><li><strong>تقليل الحمل على الخادم:</strong> تقييد وصول الروبوتات إلى الموارد غير الهامة.</li><li><strong>حماية البيانات الحساسة:</strong> تحديد الملفات أو المجلدات التي لا ينبغي زحفها.</li></ul><h3>2. مثال على ملف robots.txt</h3><pre><code class=\"language-plaintext\"># السماح لجميع الروبوتات بالزحف إلى الموقع\nUser-agent: *\n\n# منع الروبوتات من الزحف إلى مجلد الإدارة\nDisallow: /admin/\n\n# منع الوصول إلى ملفات معينة\nDisallow: /confidential-data.pdf\n\n# السماح بكل شيء باستثناء ملفات JS وCSS\nAllow: /static/\nDisallow: /*.js$\nDisallow: /*.css$\n\n# تحديد موقع خريطة الموقع\nSitemap: https://www.example.com/sitemap.xml</code></pre><h3>3. خطوات تكوين ملف robots.txt</h3><h4>الخطوة 1: إنشاء ملف robots.txt</h4><p>قم بإنشاء ملف باسم <code>robots.txt</code> في الدليل الجذري لمشروعك. أضف القواعد اللازمة للتحكم في وصول الروبوتات.</p><h4>الخطوة 2: إضافة ملف robots.txt إلى مشروعك</h4><p>في مشروع React أو Vite، ضع الملف في مجلد <code>public/</code>. عند النشر، سيكون الملف متاحًا عبر الرابط <code>https://www.example.com/robots.txt</code>.</p><h4>الخطوة 3: اختبار ملف robots.txt</h4><p>استخدم الأداة <a href=\"https://technicalseo.com/tools/robots-txt/\" target=\"_blank\">robots.txt Validator and Testing Tool</a> للتأكد من أن الإعدادات صحيحة. <img src=\"/assets/images/articles/chekRobot.PNG\" alt=\"لقطة شاشة لاختبار ملف robots.txt\" style=\"display:block; margin:20px auto; max-width:100%; border-radius:8px;\"/></p><h3>4. أفضل الممارسات لملف robots.txt</h3><ul><li><strong>لا تحظر الملفات الأساسية:</strong> تأكد من أن ملفات CSS وJS الضرورية غير محظورة.</li><li><strong>أضف خريطة الموقع:</strong> حدد موقع ملف خريطة الموقع XML. لمزيد من المعلومات، راجع <a href=\"/article/5/\" target=\"_blank\">إنشاء وإضافة خريطة موقع XML</a>.</li><li><strong>تجنب استخدام robots.txt لحماية البيانات الحساسة:</strong> لا يزال من الممكن الوصول إلى الملفات المحظورة عبر روابط مباشرة.</li></ul><h3>5. مثال لمشروع React</h3><pre><code class=\"language-plaintext\">User-agent: *\nDisallow: /private/\nDisallow: /admin/\nAllow: /static/\nSitemap: https://www.myreactapp.com/sitemap.xml</code></pre><h3>الخاتمة</h3><p>يضمن ملف <code>robots.txt</code> الذي تم تكوينه بشكل جيد أن تقوم محركات البحث بالزحف فقط إلى الأجزاء ذات الصلة من موقعك. هذا يعزز تحسين محركات البحث (SEO) مع حماية مواردك.</p>"
}
