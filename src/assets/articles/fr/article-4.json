{
  "id": 4,
  "title": "Comprendre et configurer robots.txt",
  "image": "robots-txt.webp",
  "excerpt": "Découvrez comment créer et configurer un fichier robots.txt pour contrôler l'exploration de votre site par les moteurs de recherche.",
  "content": "<p><img src=\"/assets/images/articles/robot.png\" alt=\"Capture d'écran d'une erreur robots.txt non valide\" style=\"display:block; margin:20px auto; max-width:100%; border-radius:8px;\"/> Le fichier <code>robots.txt</code> est un élément clé pour contrôler l'accès des moteurs de recherche à votre site. Il permet de spécifier quelles sections de votre site doivent ou ne doivent pas être explorées par les robots d'exploration.</p><h3>1. Pourquoi utiliser robots.txt ?</h3><p>Voici les principales raisons d'utiliser un fichier <code>robots.txt</code> :</p><ul><li><strong>Améliorer le SEO :</strong> Empêcher l'indexation de pages inutiles ou sensibles.</li><li><strong>Réduire la charge sur le serveur :</strong> Limiter l'accès des robots à des ressources non critiques.</li><li><strong>Protéger des données sensibles :</strong> Indiquer que certains fichiers ou répertoires ne doivent pas être explorés.</li></ul><h3>2. Exemple d'un fichier robots.txt</h3><pre><code class=\"language-plaintext\"># Autorise tous les robots à explorer le site\nUser-agent: *\n\n# Bloque les robots d'explorer le dossier admin\nDisallow: /admin/\n\n# Bloque des fichiers spécifiques\nDisallow: /confidential-data.pdf\n\n# Autorise tout sauf les fichiers JS et CSS\nAllow: /static/\nDisallow: /*.js$\nDisallow: /*.css$\n\n# Spécifie l'emplacement du fichier Sitemap\nSitemap: https://www.example.com/sitemap.xml</code></pre><h3>3. Étapes pour configurer un fichier robots.txt</h3><h4>Étape 1 : Créer un fichier robots.txt</h4><p>Créez un fichier nommé <code>robots.txt</code> dans le répertoire racine de votre projet. Ajoutez les règles nécessaires pour contrôler l'accès des robots.</p><h4>Étape 2 : Ajouter robots.txt à votre déploiement</h4><p>Dans un projet React ou Vite, placez le fichier dans le répertoire <code>public/</code>. Lors du déploiement, il sera accessible via l'URL <code>https://www.example.com/robots.txt</code>.</p><h4>Étape 3 : Tester votre fichier robots.txt</h4><p>Utilisez l'outil <a href=\"https://technicalseo.com/tools/robots-txt/\" target=\"_blank\">robots.txt Validator and Testing Tool</a> pour vérifier que votre configuration est correcte. <img src=\"/assets/images/articles/chekRobot.PNG\" alt=\"Capture d'écran de vérification du fichier robots.txt\" style=\"display:block; margin:20px auto; max-width:100%; border-radius:8px;\"/></p><h3>4. Bonnes pratiques pour robots.txt</h3><ul><li><strong>Ne bloquez pas les fichiers essentiels :</strong> Vérifiez que les fichiers CSS et JS nécessaires ne sont pas bloqués.</li><li><strong>Ajoutez un Sitemap :</strong> Spécifiez l'emplacement de votre fichier sitemap XML. Pour en savoir plus, consultez <a href=\"/article/5/\" target=\"_blank\">Créer et ajouter un plan de site XML</a>.</li><li><strong>Évitez d'utiliser robots.txt pour sécuriser des données sensibles :</strong> Les fichiers bloqués peuvent être accessibles via leur URL directe.</li></ul><h3>5. Exemple pour un projet React</h3><pre><code class=\"language-plaintext\">User-agent: *\nDisallow: /private/\nDisallow: /admin/\nAllow: /static/\nSitemap: https://www.myreactapp.com/sitemap.xml</code></pre><h3>Conclusion</h3><p>Un fichier <code>robots.txt</code> bien configuré permet aux moteurs de recherche d'explorer uniquement les parties pertinentes de votre site. Cela améliore votre SEO tout en protégeant vos ressources.</p>"
}
